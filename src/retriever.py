import json
import numpy as np
from sentence_transformers import SentenceTransformer, util
from estructura_cas import DescripcioProblema

class Retriever:
    def __init__(self, path_base_casos):
        # 1. Carregar la base de casos
        try:
            with open(path_base_casos, 'r', encoding='utf-8') as f:
                self.base_casos = json.load(f)
        except FileNotFoundError:
            print(f"‚ùå Error: No es troba '{path_base_casos}'. Has executat el generador?")
            self.base_casos = []
            return
        
        # 2. Carregar el model d'Embeddings (Petit i r√†pid)
        print("üß† Carregant model de llenguatge (MiniLM) per a la similitud sem√†ntica...")
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # 3. Pre-calcular els embeddings dels casos existents (Indexaci√≥)
        # Concatenem estil i tipus d'event per crear la "signatura" del cas
        self.corpus_text = [
            f"{c['problema']['estil_culinari']} {c['problema']['tipus_esdeveniment']} {c['problema']['formalitat']}" 
            for c in self.base_casos
        ]
        # Aix√≤ converteix el text en vectors num√®rics
        self.corpus_embeddings = self.model.encode(self.corpus_text, convert_to_tensor=True)
        print(f"‚úÖ Retriever inicialitzat amb {len(self.base_casos)} casos indexats.")

    def _similitud_numerica(self, peticio: DescripcioProblema, cas_dict):
        """Calcula una puntuaci√≥ (0-1) basada en restriccions dures."""
        
        # 1. Pressupost (Factor cr√≠tic)
        preu_cas = cas_dict['solucio']['preu_total']
        if preu_cas > peticio.pressupost_max:
            # Si es passa de pressupost, penalitzem molt (per√≤ no descartem del tot per si l'estil √©s perfecte)
            sim_preu = 0.2
        else:
            sim_preu = 1.0
            
        # 2. Comensals (Factor log√≠stic)
        # Utilitzem una funci√≥ gaussiana simple: com m√©s lluny, menys similitud
        diff = abs(peticio.n_comensals - cas_dict['problema']['n_comensals'])
        sim_comensals = 1 / (1 + 0.01 * diff) 

        return (sim_preu * 0.6) + (sim_comensals * 0.4)

    def recuperar_casos_similars(self, peticio: DescripcioProblema, k=3):
        """
        Retorna els k casos m√©s similars combinant Sem√†ntica + Num√®rica.
        """
        if not self.base_casos:
            return []

        # 1. Crear embedding de la PETICI√ì de l'usuari
        query_text = f"{peticio.estil_culinari} {peticio.tipus_esdeveniment} {peticio.formalitat}"
        query_embedding = self.model.encode(query_text, convert_to_tensor=True)

        # 2. Calcular Similitud Cosinus (Sem√†ntica)
        # Aix√≤ ens diu com d'aprop estan els conceptes (ex: "Japon√®s" vs "Oriental")
        cos_scores = util.cos_sim(query_embedding, self.corpus_embeddings)[0]

        resultats = []

        # 3. Combinar amb Similitud Num√®rica i crear llista de candidats
        for idx, score_sem_tensor in enumerate(cos_scores):
            cas = self.base_casos[idx]
            score_sem = float(score_sem_tensor)
            
            score_num = self._similitud_numerica(peticio, cas)
            
            # PONDERACI√ì FINAL: 
            # 70% Estil (Sem√†ntica) + 30% Restriccions (Num√®rica)
            # Aix√≤ prioritza que el men√∫ "inspiri" l'estil, encara que haguem d'adaptar preu despr√©s.
            score_final = (score_sem * 0.7) + (score_num * 0.3)
            
            resultats.append({
                'cas': cas,
                'score_final': score_final,
                'detall': {
                    'sim_semantica': round(score_sem, 4),
                    'sim_numerica': round(score_num, 4)
                }
            })

        # 4. Ordenar per millor puntuaci√≥ i retornar els top K
        resultats.sort(key=lambda x: x['score_final'], reverse=True)
        return resultats[:k]